#!/home/pipeline-stable/.conda/envs/pipeline/bin/python
"""
Pipeline Trigger Service

This script monitors directories for new images and processes them directly.
It uses the existing Monitor class from the pipeline codebase.
"""

import time
import logging
import glob
from pathlib import Path
from pipeline.services.monitor import Monitor
from pipeline.services.scheduler import Scheduler
from pipeline.services.blueprint import Blueprint
from pipeline.const import RAWDATA_DIR


# Set up logging with rotation
from logging.handlers import RotatingFileHandler

# Create rotating file handler (max 10MB per file, keep 5 backup files = 50MB total)
file_handler = RotatingFileHandler(
    "/var/log/pipeline-trigger.log",
    maxBytes=10 * 1024 * 1024,  # 10MB
    backupCount=5,  # Keep 5 backup files
)

file_handler.setLevel(logging.INFO)
file_handler.setFormatter(logging.Formatter("%(asctime)s - Monitor - %(levelname)s - %(message)s"))

# Console handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(logging.Formatter("%(asctime)s - Monitor - %(levelname)s - %(message)s"))

# Configure root logger
logging.basicConfig(
    level=logging.INFO,
    handlers=[file_handler, console_handler],
)
logger = logging.getLogger(__name__)


def check_too(image_path):
    file_path = Path(image_path)
    rawdata_path = Path(RAWDATA_DIR)
    relative_path = file_path.relative_to(rawdata_path)
    path_parts = relative_path.parts
    if path_parts and path_parts[0].startswith("7DT"):
        if path_parts[1].endswith("_ToO"):
            return True
        else:
            return False


def get_too_images(image_path):
    """
    Get images from the corresponding ToO directory for a non-ToO image.
    Returns list of image paths if ToO directory exists, None otherwise.
    """
    file_path = Path(image_path)
    rawdata_path = Path(RAWDATA_DIR)
    relative_path = file_path.relative_to(rawdata_path)
    path_parts = list(relative_path.parts)
    if path_parts and path_parts[0].startswith("7DT"):
        if not path_parts[1].endswith("_ToO"):
            # Construct path to corresponding ToO directory
            too_dir_name = path_parts[1] + "_ToO"
            too_path = rawdata_path / path_parts[0] / too_dir_name
            if too_path.exists():
                image_list = list(glob.glob(str(too_path / "*.fits")))
                return image_list if image_list else None
    return None


def run_image_processing(image_paths, is_too=False):
    br = Blueprint.from_list(
        list_of_images=image_paths,
        is_too=is_too,
    )
    br.create_config(is_too=is_too, overwrite=False)
    br.create_schedule(is_too=is_too, input_type="Daily")
    sc = Scheduler(br.schedule, use_system_queue=True)
    sc.start_system_queue()


def get_fits_files(image_paths):
    return [image for image in image_paths if image.endswith(".fits")]


def process_new_images(image_paths):
    """
    Process new images using the existing pipeline infrastructure.
    Each image set runs in its own tmux session for isolation and monitoring.

    Logic:
    - Images in _ToO directories: process with is_too=True
    - Images in non-_ToO directories: add corresponding ToO images and process with is_too=False
    """
    try:
        logger.info(f"New images detected: {len(image_paths)} images")
        image_paths = get_fits_files(image_paths)
        # Separate ToO and non-ToO images
        too_image_paths = [image for image in image_paths if check_too(image)]
        non_too_image_paths = [image for image in image_paths if not check_too(image)]

        # Process non-ToO images: add corresponding ToO images and process with is_too=False
        if len(non_too_image_paths) > 0:
            logger.info(f"Non-ToO images detected. A daily image processing will be triggered.")
            # Collect all ToO images for non-ToO directories
            all_too_images = set()
            for image in non_too_image_paths:
                too_images = get_too_images(image)
                if too_images:
                    all_too_images.update(too_images)

            # Combine non-ToO images with their corresponding ToO images
            combined_images = non_too_image_paths + list(all_too_images)
            if len(combined_images) > 0:
                logger.info(
                    f"Processed {len(combined_images)} daily images, including {len(all_too_images)} ToO images observed on the same day"
                )
                run_image_processing(combined_images, is_too=False)
        elif len(too_image_paths) > 0:
            logger.info(f"ToO images detected. A ToO image processing will be triggered.")
            logger.info(f"Processed {len(too_image_paths)} ToO images")
            run_image_processing(too_image_paths, is_too=True)

    except Exception as e:
        logger.error(f"Error processing images: {e}", exc_info=True)


def start_trigger_monitoring():
    """Start the trigger monitoring service using the existing Monitor class."""
    # RAWDATA_DIR = "/lyman/data2/obsdata/"
    # Create the monitor using the existing codebase

    sc = Scheduler(use_system_queue=True)
    sc.rerun_failed_jobs()
    sc.update_process_status()

    monitor = Monitor(base_path=Path(RAWDATA_DIR))
    monitor.add_callback(process_new_images)
    observer = monitor.start()

    logger.info("Trigger service started - monitoring directories for new images")

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("Trigger service stopping...")
        observer.stop()

    observer.join()
    logger.info("Trigger service stopped")


if __name__ == "__main__":
    start_trigger_monitoring()
