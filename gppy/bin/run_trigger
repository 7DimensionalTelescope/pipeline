#!/usr/bin/env python
"""
Pipeline Trigger Service

This script monitors directories for new images and processes them directly.
It uses the existing Monitor class from the gppy codebase.
"""

import time
import logging
from pathlib import Path
from gppy.services.monitor import Monitor
from gppy.wrapper import DataReduction

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("/var/log/pipeline-trigger.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


def process_new_images(image_paths):
    """
    Process new images using the existing pipeline infrastructure.
    This is the same function used in the original start_monitoring.
    """
    try:
        logger.info(f"Processing {len(image_paths)} new images")
        dr = DataReduction.from_list(image_paths)
        dr.create_config()
        dr.process_all()
        logger.info(f"Successfully processed {len(image_paths)} images")
    except Exception as e:
        logger.error(f"Error processing images: {e}")


def start_trigger_monitoring():
    """Start the trigger monitoring service using the existing Monitor class."""
    from gppy.const import RAWDATA_DIR

    # Create the monitor using the existing codebase
    monitor = Monitor(base_path=Path(RAWDATA_DIR))
    monitor.add_callback(process_new_images)
    observer = monitor.start()

    logger.info("Trigger service started - monitoring directories for new images")

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("Trigger service stopping...")
        observer.stop()

    observer.join()
    logger.info("Trigger service stopped")


if __name__ == "__main__":
    start_trigger_monitoring()
